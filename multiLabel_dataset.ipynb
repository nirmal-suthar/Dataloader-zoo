{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiLabel_dataset(Dataset):\n",
    "    \"\"\"Dataset class for the multiLabel dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, attr_path, selected_attrs = None, crop_size = 128, mode = 'train'):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize and preprocess the dataset.\n",
    "        \n",
    "        args\n",
    "        image_dir: (str) path for inputs\n",
    "        attr_path: (str) path of file containing attributes label\n",
    "            format of attr path :- \n",
    "            first line: number of images\n",
    "            ex. 202599\n",
    "            second line: names of all atrributes seperated by commas\n",
    "            ex. 5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs\n",
    "            remaining lines: name of image and then int (1 : present, -1 : not present) seperated by commas \n",
    "            ex. 000001.jpg -1  1  1 -1 -1 -1\n",
    "        selected_attrs: (list, optional) list of atttributes for processing labels. Default, all attributes\n",
    "                        in attributes file will be use to process labels.\n",
    "        \n",
    "        crop_size: (int, optional)\n",
    "        mode: ({'train','test'}, optional)\n",
    "        \n",
    "        returns: \n",
    "        one image and corresponding one hot vector\n",
    "        \n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.attr_path = attr_path\n",
    "        self.selected_attrs = selected_attrs\n",
    "        \n",
    "        transform = []\n",
    "        # to be extended for data augmentation\n",
    "        \n",
    "#         if mode == 'train':\n",
    "#             transform.append(T.RandomHorizontalFlip())\n",
    "        \n",
    "        transform.append(T.CenterCrop(crop_size))\n",
    "        transform.append(T.ToTensor())\n",
    "        transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "        transform = T.Compose(transform)\n",
    "            \n",
    "        self.mode = mode\n",
    "        self.train_dataset = []\n",
    "        self.test_dataset = []\n",
    "        self.attr2idx = {}\n",
    "        self.idx2attr = {}\n",
    "        self.preprocess()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.num_images = len(self.train_dataset)\n",
    "        else:\n",
    "            self.num_images = len(self.test_dataset)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Preprocess the attribute file.\"\"\"\n",
    "        lines = [line.rstrip() for line in open(self.attr_path, 'r')]\n",
    "        all_attr_names = lines[1].split()\n",
    "        \n",
    "        if isinstance(self.selected_attrs, None):\n",
    "            self.selected_attrs = all_attr_names\n",
    "        \n",
    "        for i, attr_name in enumerate(all_attr_names):\n",
    "            self.attr2idx[attr_name] = i\n",
    "            self.idx2attr[i] = attr_name\n",
    "\n",
    "        lines = lines[2:]\n",
    "        random.seed(1234)\n",
    "        random.shuffle(lines)\n",
    "        for i, line in enumerate(lines):\n",
    "            split = line.split()\n",
    "            filename = split[0]\n",
    "            values = split[1:]\n",
    "\n",
    "            label = []\n",
    "            for attr_name in self.selected_attrs:\n",
    "                idx = self.attr2idx[attr_name]\n",
    "                label.append(values[idx] == '1')\n",
    "\n",
    "            if (i+1) < 2000:\n",
    "                self.test_dataset.append([filename, label])\n",
    "            else:\n",
    "                self.train_dataset.append([filename, label])\n",
    "\n",
    "        print('Finished preprocessing the dataset...')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return one image and its corresponding attribute label.\"\"\"\n",
    "        dataset = self.train_dataset if self.mode == 'train' else self.test_dataset\n",
    "        filename, label = dataset[index]\n",
    "        image = Image.open(os.path.join(self.image_dir, filename))\n",
    "        return self.transform(image), torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of images.\"\"\"\n",
    "        return self.num_images\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
